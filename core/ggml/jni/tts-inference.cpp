//ref/original author:https://github.com/PABannier/bark.cpp/blob/main/examples/main/main.cpp


#include <iostream>
#include <tuple>
#include <string>
#include <vector>
#include <string>
#include <thread>

#include "bark.h"
#include "ggml.h"
#include "ggml-jni.h"

#define DR_WAV_IMPLEMENTATION
#include "dr_wav.h"

#define SAMPLE_RATE 24000

struct bark_params {
    // Number of threads used for audio generation.
    int32_t n_threads = std::min(4, (int32_t)std::thread::hardware_concurrency());

    // User prompt.
    std::string prompt = "This is an audio generated by bark.cpp";

    // Location of model weights.
    std::string model_path = "./ggml_weights";

    // Destination path for generated WAV file.
    std::string dest_wav_path = "output.wav";

    // Seed for reproducibility in token sampling.
    int32_t seed = 0;
};


/**
 * @brief Writes a WAV file from disk and stores the audio data in a vector of floats.
 *
 * @param in_path Path to the input WAV file.
 * @param audio_arr Vector to store the audio data.
 * @return true If the file was successfully read.
 * @return false If the file could not be read.
 */
static void write_wav_on_disk(std::vector<float>& audio_arr, std::string dest_path) {
    drwav_data_format format;
    format.bitsPerSample = 32;
    format.sampleRate = SAMPLE_RATE;
    format.container = drwav_container_riff;
    format.channels = 1;
    format.format = DR_WAVE_FORMAT_IEEE_FLOAT;

    drwav wav;
    drwav_init_file_write(&wav, dest_path.c_str(), &format, NULL);
    drwav_uint64 frames = drwav_write_pcm_frames(&wav, audio_arr.size(), audio_arr.data());
    drwav_uninit(&wav);

    LOGGD("%s: Number of frames written = %lld.\n", __func__, frames);
    GGML_JNI_NOTIFY("%s: Number of frames written = %lld.\n", __func__, frames);
}


static void bark_print_progress_callback(struct bark_context * bctx, enum bark_encoding_step step, int progress, void * user_data) {
    if (step == bark_encoding_step::SEMANTIC) {
        LOGGD("Generating semantic tokens... %d%%", progress);
        GGML_JNI_NOTIFY("Generating semantic tokens... %d%%", progress);
    } else if (step == bark_encoding_step::COARSE) {
        LOGGD("Generating coarse tokens... %d%%", progress);
        GGML_JNI_NOTIFY("Generating coarse tokens... %d%%", progress);
    } else if (step == bark_encoding_step::FINE) {
        LOGGD("Generating fine tokens... %d%%", progress);
        GGML_JNI_NOTIFY("Generating fine tokens... %d%%", progress);
    }
}


int  tts_inference(const char * sz_model_path, const char * prompt, int bench_type, int num_threads, int n_backend_type) {
    ggml_time_init();
    const int64_t t_main_start_us = ggml_time_us();

    bark_params params;
    bark_verbosity_level verbosity = bark_verbosity_level::LOW;

    params.n_threads = num_threads;
    params.prompt = prompt;
    params.model_path = sz_model_path;
    params.dest_wav_path = "/sdcard/kantv/output.wav"; //TODO:hardcode path
    LOGGD("prompt %s", prompt);
    LOGGD("model %s", sz_model_path);
    // initialize bark context
    struct bark_context_params ctx_params = bark_context_default_params();

    ctx_params.verbosity = verbosity;
    ctx_params.progress_callback = bark_print_progress_callback;
    ctx_params.progress_callback_user_data = nullptr;

    struct bark_context *bctx = bark_load_model(params.model_path.c_str(), ctx_params, params.seed);
    if (!bctx) {
        LOGGW("%s: Could not load model\n", __func__);
        return 1;
    }

    // generate audio
    if (!bark_generate_audio(bctx, params.prompt.c_str(), params.n_threads)) {
        LOGGW("%s: An error occurred in bark_generate_audio. If the problem persists, feel free to open an issue to report it.\n", __func__);
        GGML_JNI_NOTIFY("%s: An error occurred in bark_generate_audio\n", __func__);
        return 1;
    }

    const float *audio_data = bark_get_audio_data(bctx);
    if (audio_data == NULL) {
        LOGGD("%s: Could not get audio data\n", __func__);
        return 1;
    }

    const int audio_arr_size = bark_get_audio_data_size(bctx);

    std::vector<float> audio_arr(audio_data, audio_data + audio_arr_size);

    write_wav_on_disk(audio_arr, params.dest_wav_path);

    // report timing
    {
        const int64_t t_main_end_us = ggml_time_us();
        const int64_t t_load_us = bark_get_load_time(bctx);
        const int64_t t_eval_us = bark_get_eval_time(bctx);

        LOGGD("\n\n");
        LOGGD("%s:     load time = %8.2f ms\n", __func__, t_load_us / 1000.0f);
        LOGGD("%s:     eval time = %8.2f ms\n", __func__, t_eval_us / 1000.0f);
        LOGGD("%s:    total time = %8.2f ms\n", __func__, (t_main_end_us - t_main_start_us) / 1000.0f);
    }

    bark_free(bctx);

    return 0;
}
